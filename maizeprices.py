# -*- coding: utf-8 -*-
"""MaizePrices.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlOQbys_kXA-r1a9MsUyrU6OWp-jI9Fk
"""

#Modules
import pandas as pd
import numpy as np
import warnings
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
warnings.filterwarnings("ignore")

# Load data
df = pd.read_csv("Market Prices Search.csv")
print("Raw data shape:", df.shape)
# View first rows
print(df.head())

# keep only dry maize
df = df[df["Commodity"].str.lower().str.contains("maize")]

# convert price to numeric
df["Retail"] = pd.to_numeric(
    df["Retail"]
    .str.replace("/Kg", "", regex=False),
    errors="coerce"
)
# convert date to datetime
df["Date"] = pd.to_datetime(df["Date"])
print("After cleaning:", df.shape)

#Weekly Aggregation
weekly = (
    df.groupby(["County", pd.Grouper(key="Date", freq="W-MON")])["Retail"]
      .mean()
      .reset_index()
      .rename(columns={"Retail": "price"})
)

weekly = weekly.sort_values("Date").reset_index(drop=True)
print("Weekly data shape:", weekly.shape)

# ==========================================================
# STEP 4: FEATURE ENGINEERING
# ==========================================================

# Lag features
for lag in [1, 2, 3]:
    weekly[f"lag_{lag}"] = weekly.groupby("County")["price"].shift(lag)

# Rolling statistics
weekly["roll_mean_4"] = (
    weekly.groupby("County")["price"]
          .rolling(4).mean()
          .reset_index(level=0, drop=True)
)

weekly["roll_std_4"] = (
    weekly.groupby("County")["price"]
          .rolling(4).std()
          .reset_index(level=0, drop=True)
)

# Calendar features
weekly["week"] = weekly["Date"].dt.isocalendar().week.astype(int)
weekly["month"] = weekly["Date"].dt.month
weekly["year"] = weekly["Date"].dt.year

# Encode counties
weekly = pd.get_dummies(weekly, columns=["County"])

# Remove NA rows
weekly = weekly.dropna().reset_index(drop=True)
print("After feature engineering:", weekly.shape)

# ==========================================================
# STEP 5: TIME-BASED TRAIN / VALIDATION SPLIT
# ==========================================================

split_date = weekly["Date"].quantile(0.85)

train = weekly[weekly["Date"] <= split_date]
val   = weekly[weekly["Date"] > split_date]

X_train = train.drop(columns=["price", "Date"])
y_train = train["price"]

X_val = val.drop(columns=["price", "Date"])
y_val = val["price"]

print("Train size:", X_train.shape)
print("Validation size:", X_val.shape)

# ==========================================================
# STEP 6: BASELINE MODEL (FOR COMPARISON)
# ==========================================================

baseline_model = LGBMRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=5,
    num_leaves=24,
    min_data_in_leaf=20,
    random_state=42,
    verbose=-1
)

baseline_model.fit(X_train, y_train)
baseline_preds = baseline_model.predict(X_val)

baseline_mae = mean_absolute_error(y_val, baseline_preds)
baseline_rmse = np.sqrt(mean_squared_error(y_val, baseline_preds))

print("\nBASELINE PERFORMANCE")
print(f"MAE  : {baseline_mae:.2f}")
print(f"RMSE : {baseline_rmse:.2f}")
print(f"Score: {(baseline_mae + baseline_rmse)/2:.2f}")

# ==========================================================
# STEP 7: LIGHTGBM HYPERPARAMETER TUNING
# ==========================================================

param_grid = [
    {"max_depth": 5, "num_leaves": 24},
    {"max_depth": 6, "num_leaves": 32}
]

results = []

for params in param_grid:
    model = LGBMRegressor(
        n_estimators=800,
        learning_rate=0.03,
        subsample=0.9,
        colsample_bytree=0.9,
        min_data_in_leaf=20,
        random_state=42,
        verbose=-1,
        **params
    )

    model.fit(X_train, y_train)
    preds = model.predict(X_val)

    mae = mean_absolute_error(y_val, preds)
    rmse = np.sqrt(mean_squared_error(y_val, preds))

    results.append({
        "max_depth": params["max_depth"],
        "num_leaves": params["num_leaves"],
        "MAE": mae,
        "RMSE": rmse,
        "Score": (mae + rmse) / 2
    })

results_df = pd.DataFrame(results).sort_values("Score")
print("\nTUNING RESULTS")
print(results_df)

# ==========================================================
# STEP 8: TRAIN FINAL MODEL ON ALL DATA
# ==========================================================

best = results_df.iloc[0]

final_model = LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.025,
    max_depth=int(best["max_depth"]),
    num_leaves=int(best["num_leaves"]),
    subsample=0.9,
    colsample_bytree=0.9,
    min_data_in_leaf=20,
    random_state=42,
    verbose=-1
)

X_full = weekly.drop(columns=["price", "Date"])
y_full = weekly["price"]

final_model.fit(X_full, y_full)

# ==========================================================
# STEP 9: RECURSIVE FORECAST FUNCTION (FIXED)
# ==========================================================

def recursive_forecast(last_row, model, steps=6):
    preds = []
    current = last_row.copy()
    feature_names = current.index.tolist()

    for _ in range(steps):
        current_df = pd.DataFrame([current.values], columns=feature_names)
        pred = model.predict(current_df)[0]
        preds.append(pred)

        current["lag_3"] = current["lag_2"]
        current["lag_2"] = current["lag_1"]
        current["lag_1"] = pred

    return preds

# ==========================================================
# STEP 10: CREATE SUBMISSION FILE
# ==========================================================

counties = [
    "Kiambu",
    "Kirinyaga",
    "Mombasa",
    "Nairobi",
    "Uasin-Gishu"
]

forecast_weeks = [
    "Week_50", "Week_51", "Week_52",
    "Week_01", "Week_02", "Week_03"
]

rows = []

for county in counties:
    county_data = weekly[weekly[f"County_{county}"] == 1]
    last_row = county_data.drop(columns=["price", "Date"]).iloc[-1]

    preds = recursive_forecast(last_row, final_model, steps=6)

    for week, price in zip(forecast_weeks, preds):
        rows.append({
            "ID": f"{county}_{week}",
            "Target_RMSE": price,
            "Target_MAE": price
        })

submission = pd.DataFrame(rows)
submission.to_csv("maize_price_submission.csv", index=False)

print("\nSUBMISSION PREVIEW")
print(submission.head(10))
print("\nFinal submission shape:", submission.shape)

